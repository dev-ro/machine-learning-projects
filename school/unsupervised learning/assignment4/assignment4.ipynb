{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9a6d935dfc5f458f52a6d5ee8da6c3f",
     "grade": false,
     "grade_id": "cell-c18d184342185ba6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Table of Contents\n",
    "- **[Assignment 4 Description](#Topic0)**\n",
    "  - [Task 1 - Import CSV Sensor Data file](#t1)\n",
    "  - [Task 2 - Standard train_test_split](#t2)\n",
    "  - [Task 3 - Build a baseline Tree model](#t3)\n",
    "  - [Task 4 - Baseline Tree model questions](#t4)\n",
    "  - [Task 5a - A custom train_test_split function](#t5a)\n",
    "  - [Task 5b - Run a baseline_model](#t5b)\n",
    "  - [Task 5c - Custom train/test split questions](#t5c)\n",
    "  - [Task 6 - Confusion Matrix](#t6)\n",
    "    - [Visualizing the Confusion Matrix](#vcm)\n",
    "  - [Task 7 - Basic Confusion Matrix Understanding](#t7)\n",
    "  - [Task 8 - Feature Importance, part 1](#t8)\n",
    "  - [Task 9 - Feature Importance, part 2](#t9)  \n",
    "    - [Scores Plot](#scoresplot)\n",
    "  - [Task 10 - Final project](#t10)\n",
    "    - [Task 10 Autograder Scoring](#t10ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either of the following is no longer\n",
    "# necessary for matplotlib in notebooks.\n",
    "# The import statement has you covered!\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b55e4f31b159cfea2250da44210155f",
     "grade": false,
     "grade_id": "cell-371f2ff64fb68763",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<a id='Topic0'></a>\n",
    "# Assignment 4 - Tree-based classification & Synthesis Project\n",
    "\n",
    "### Physiological Sensor Data Analysis (100 points)\n",
    "This synthesis project is based on a dataset of physiological sensor measurements collected from Smartphone based sensors. The original research sought to determine the particular activity of the subject based on the physiological measurements obtained from wearables and a SmartPhone. The physiological measurements were used to depict the test subject in one of four activities as follows:  \n",
    "   - neutral\n",
    "   - emotional\n",
    "   - mental\n",
    "   - physical  \n",
    " \n",
    "Your task will be to produce a model that, based on a limited number of features, returns the best possible estimate of the activity being performed by the test subject. While the original analysis utilized more advanced Machine Learning methods, we will concentrate on the supervised learning methods covered in this course.  \n",
    "\n",
    "The sensor dataset consists of 4480 rows, each with the subject ID, the activity label and 533 measurement features! Each of the 40 test volunteers were subjected to a series of 28 data collection events for each of the four activity types presented above. As you explore this data, you will find that the features are arranged by a particular measurement mode, each consisting of similar statistical values.  \n",
    "Before we get started, it will be necessary to ingest and prepare our data for training and testing purposes.  \n",
    "\n",
    "**Notes**  \n",
    " - Any available random_state or seed values should be initialized with an integer value of 42.\n",
    " - Some standard package imports have been provided below.\n",
    " - Additional import deemed necessary for your analysis can be added in the cell following.  \n",
    " \n",
    " <a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings only when absolutely necessary\n",
    "# Warnings are in place for a reason!\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f00477711cbe8f337a840b07c1c02d1a",
     "grade": false,
     "grade_id": "cell-93298b856670623e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# useful python standard libraries\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "\n",
    "# import core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpful SciKit-Learn libraries\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d6646c4fd68fa2df4bc6aee78b27488",
     "grade": false,
     "grade_id": "cell-f7bc50deed21528d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "up, down = True, False\n",
    "\n",
    "# path/filename to dataset\n",
    "sensor_data = \"assets/sensor_data.csv\"\n",
    "\n",
    "# We will use this variable name multiple times\n",
    "base_feature_selector = \"_mad_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "\n",
    "## Additional imports can be inlcuded here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from math import ceil\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f010dcda16b5f35c7adbc46f8fb099d5",
     "grade": false,
     "grade_id": "cell-366227f52585e158",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t1'></a>\n",
    "## Task 1 - Import CSV Sensor Data file (2 points).\n",
    " - The first order of business is to read the data file, '_sensor_data.csv_ ', from the '_assets/_ ' folder.\n",
    " - Your function should accept zero arguments and return a Pandas DataFrame.\n",
    " - Be aware that the activity labels are in a format that may or may not work with your chosen models. If you choose to reassign the activity labels, use the following:  \n",
    "    - **'neutral' == 1**\n",
    "    - **'emotional' == 2**\n",
    "    - **'mental' == 3**\n",
    "    - **'physical' == 4**  \n",
    "    \n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06e9ab7a0c2305465b288755c76090fa",
     "grade": true,
     "grade_id": "cell-df67153258c0d72e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "875e0fb6cee51813a0170950acdfac90",
     "grade": false,
     "grade_id": "cell-323ce9af9affa7e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sensor_data():\n",
    "    try:\n",
    "        return pd.read_pickle('sensor_data.pkl')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        df = pd.read_csv('assets/sensor_data.csv')\n",
    "\n",
    "        # make alternate label assignment in numeric form\n",
    "        activities = [\n",
    "            ('neutral', 1),\n",
    "            ('emotional', 2),\n",
    "            ('mental', 3),\n",
    "            ('physical', 4)\n",
    "        ]\n",
    "\n",
    "        df['Activity_Label'] = df['Activity_Label'].map(dict(activities))\n",
    "\n",
    "        # save the dataframe to a pickle file\n",
    "        df.to_pickle('sensor_data.pkl')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# get_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e834ef5163def337dafd1fe0a829dc0",
     "grade": true,
     "grade_id": "cell-d56b92a082173913",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = get_sensor_data()\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, pd.DataFrame\n",
    "), \"Task 1: Your get_sensor_data function must return a Pandas DataFrame.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans.iloc[0][2], np.float64\n",
    "), \"Task 1: The dtype of the first row, third column, is incorrect.\"\n",
    "\n",
    "# Some hidden tests\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c08dc744468fcaed7b5222177cbab4fc",
     "grade": false,
     "grade_id": "cell-e309fa31d13a784b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t2'></a>\n",
    "## Task 2 - Standard train_test_split (3 points).\n",
    "\n",
    " - Our first exercise will be to produce a SciKit-Learn standard train/test split of a dataframe. In the following cell, complete the function that returns a standard train/test split of the sensor data.\n",
    "   - The function should accept a dataframe as produced by get_sensor_data() and a test_split value which defaults to 0.2.\n",
    "   - The function should return the standard X_train, X_test, y_train, y_test.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50375c3bc581d8a9fbde22a2ec35cf87",
     "grade": true,
     "grade_id": "cell-5f1b791501e086cb",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce5eb4171a3dce8386d1757a61a45aba",
     "grade": false,
     "grade_id": "cell-bcd3c8cc8a52f6b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def std_train_test_split(df, test_split=0.2):\n",
    "    # class label is called 'Activity_Label' in the df\n",
    "    X = df.drop('Activity_Label', axis=1)\n",
    "    y = df['Activity_Label']\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# X_train, X_test, y_train, y_test = std_train_test_split(get_sensor_data(), test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce4c7be7f35bf7624317f0377d990062",
     "grade": true,
     "grade_id": "cell-aeeea8534654fbda",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - AG tests\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "df = get_sensor_data()\n",
    "stu_ans = std_train_test_split(df)\n",
    "\n",
    "# print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Task 2: X_train should be a pd.DataFrame\"\n",
    "\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Task 2: y_train should be a pd.Series\"\n",
    "\n",
    "# Some hidden tests\n",
    "del stu_ans\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca6a005b7f8d434597fa35c5c3a17313",
     "grade": false,
     "grade_id": "cell-fca36043345da8b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t3'></a>\n",
    "## Task 3 - Build a baseline Tree model (5 Points).\n",
    "\n",
    "- Complete the following function that will establish a baseline score.  \n",
    "  - This function should retrieve and split the sensor data based on your previously constructed functions. Please use/default to, a split value of 0.2.  \n",
    "  - Using a _for loop_ or [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp), extract a list of feature names that includes the substring **base_feature_selector** defined in the **[library imports](#library-imports)** cell above.  \n",
    "  - Create a [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) with default hyperparameters and the predetermined random_state value.\n",
    "    - Train this model on the features as extracted above.  \n",
    "  - Using the classifier's [score method](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score), score the model using X_test and the previously extracted subset of features.  \n",
    "  - Finally return a tuple consisting of the list of extracted features and score.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fdf2880fc2dfc587ab2cbea55883504",
     "grade": true,
     "grade_id": "cell-ecfcc56f82cb1990",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f22ea3fe3c28b9545331247c9e4e4e",
     "grade": false,
     "grade_id": "cell-d0e06f1c335ec617",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_one():\n",
    "    df = get_sensor_data()\n",
    "    X_train, X_test, y_train, y_test = std_train_test_split(df)\n",
    "\n",
    "    features = [col for col in X_train.columns if base_feature_selector in col]\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    # fit the model on the training data with the features in features\n",
    "    model.fit(X_train[features], y_train)\n",
    "\n",
    "    # score the model with X_test and the features in features\n",
    "    score = model.score(X_test[features], y_test)\n",
    "\n",
    "    return features, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# baseline_model_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8971b50bd73bef200ba8e1e49d99ccfb",
     "grade": true,
     "grade_id": "cell-3a13464f8906cbe6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 - AG tests\n",
      "Task 3 - your answer:\n",
      "(['ECG_original_mad_13', 'ECG_RR_window_mad_27', 'ECG_amplitude_RR_mad_41', 'ECG_HR_min_div_mad_55', 'ECG_hrv_mad_79', 'ECG_PSD_mad_93', 'ECG_p_VFL_mad_107', 'ECG_p_LF_mad_121', 'ECG_p_MF_mad_135', 'ECG_p_HF_mad_149', 'ECG_p_total_LF_mad_163', 'IT_Original_mad_187', 'IT_LF_mad_202', 'IT_RF_mad_217', 'IT_BRV_mad_233', 'IT_PSD_mad_247', 'IT_VLF_mad_261', 'IT_LF_mad_275', 'IT_MF_mad_289', 'IT_HF_mad_303', 'IT_p_Total_mad_317', 'EDA_Original_mad_338', 'EDA_processed_mad_352', 'EDA_Filt1_mad_366', 'EDA_Filt2_mad_380', 'EDA_Original_mad_442', 'EDA_processed_mad_456', 'EDA_Filt1_mad_470', 'EDA_Filt2_mad_484'], 0.8314732142857143)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = baseline_model_one()\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Task 3: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Task 3: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 3: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd00be2fcb2e13c5bd51d825f23426ea",
     "grade": false,
     "grade_id": "cell-3cdcaa635d0d50b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t4'></a>\n",
    "## Task 4 - Baseline Tree model questions (3 Points).\n",
    "\n",
    "1. Does the default accuracy score returned by the model seem reasonable to you; why or why not?\n",
    "2. What might be the problem with this model or with the data?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbe07b3481fb5120d11957b6db24684",
     "grade": true,
     "grade_id": "cell-63d35379db6841e9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. nope. 83% is too low\n",
    "2. it could be that the decision tree might have bias if some variables are dominating. so we could normalize the data.\n",
    "    overfitting might be causing a lower score, so we adjust the DecisionTree parameters to see what works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7d185f4e1d0865ba0033fe9889f5cb9",
     "grade": false,
     "grade_id": "cell-6c9f9019196beec7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5a'></a>\n",
    "## Task 5a- A custom train_test_split function (10 Points).\n",
    "\n",
    " - Because of the nature of the original experiment's data collection methodology, the standard sklearn train_test_split() method cannot be applied successfully to this dataset. \n",
    " - The first significant task will be to create a 'custom_train_test_split()' function that will correctly separate train data from test data, given the structure of the data in the sensor dataset.  \n",
    " - Your function should accept two arguments:  \n",
    "   - A Pandas DataFrame such as returned by your get_sensor_data() function.\n",
    "   - An integer ___or___ float value that indicates the count or proportion of the **test** data split.\n",
    "   - In accordance with SciKit-Learn standards, split count determinations should round up.\n",
    "   - Again, any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Helpful Libraries and functions:\n",
    "   - [numpy.random](https://numpy.org/doc/stable/reference/random/index.html)\n",
    "     - numpy.random.seed()\n",
    "     - numpy.random.choice()\n",
    "   - Python [math](https://docs.python.org/3/library/math.html)  \n",
    "     - math.ceil()  \n",
    "  \n",
    " - Questions to keep in mind while creating this function:\n",
    "   - How might this function accept and use an integer or float value for the purpose of dividing the dataset?\n",
    "   - How do I ensure consistent random selection for reproducibility?\n",
    "   - Most importantly, how do I split this data to avoid one of the more devastating issues in machine learning?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fb95945bd59bdbea9f2953bd36b0634",
     "grade": true,
     "grade_id": "cell-19641eabf59826f7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"5a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f230528117213c81a6b2fd13d6b2160b",
     "grade": false,
     "grade_id": "cell-1618476de514a891",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def custom_train_test_split(df, test_split=0.2):\n",
    "\n",
    "    # if number <= 0, raise\n",
    "    if test_split <= 0:\n",
    "        raise ValueError(\"test_split must be greater than 0.\")\n",
    "\n",
    "    # if float > 1.0, then round up\n",
    "    if test_split >= 1.0:\n",
    "        test_split = ceil(test_split)\n",
    "\n",
    "    # if 0 < float < 1, sample by proportion\n",
    "    if 0 < test_split < 1.0:\n",
    "        X_test = df.sample(frac=test_split, random_state=42)\n",
    "\n",
    "    # if integer, sample by count\n",
    "    elif isinstance(test_split, int):\n",
    "        X_test = df.sample(n=test_split, random_state=42)\n",
    "\n",
    "    # if neither, raise\n",
    "    else:\n",
    "        raise ValueError(\"test_split must be either float or integer\")\n",
    "\n",
    "    # drop the test data from the dataframe to get the training data \n",
    "    X_train = df.drop(X_test.index)\n",
    "\n",
    "    # pop the Activity_Label column from the test data\n",
    "    y_test = X_test.pop('Activity_Label')\n",
    "\n",
    "    # pop the Activity_Label column from the training data\n",
    "    y_train = X_train.pop('Activity_Label')\n",
    "\n",
    "    features = [col for col in df.columns if base_feature_selector in col]\n",
    "    return X_train[features], X_test[features], y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    df.shape: (4480, 535)\n",
      "    X_train.shape: (4479, 29)\n",
      "    X_test.shape: (1, 29)\n",
      "    len(X_test): 1\n",
      "    test_split: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# use this cell to explore your solution\n",
    "\n",
    "\n",
    "def test_my_code():\n",
    "    test_split = 1.0\n",
    "    df = get_sensor_data()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(\n",
    "        df, test_split=test_split\n",
    "    )\n",
    "\n",
    "    print(f'''\n",
    "    df.shape: {df.shape}\n",
    "    X_train.shape: {X_train.shape}\n",
    "    X_test.shape: {X_test.shape}\n",
    "    len(X_test): {len(X_test)}\n",
    "    test_split: {test_split}\n",
    "    ''')\n",
    "\n",
    "    # insert additional code as necessary to complete your testing\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "test_my_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8f62714ab54649fd480d96e472f8c15",
     "grade": true,
     "grade_id": "cell-2c97a65714518e45",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5a - AG tests\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "\n",
    "test_split = 5\n",
    "df = get_sensor_data()\n",
    "\n",
    "stu_ans = custom_train_test_split(df, test_split)\n",
    "\n",
    "# print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans[0], pd.DataFrame), \"Task 5a: X_train should be a pd.DataFrame\"\n",
    "\n",
    "assert isinstance(stu_ans[2], pd.Series), \"Task 5a: y_train should be a pd.Series\"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "736a0029dfa5df3738ac141acc658bd3",
     "grade": false,
     "grade_id": "cell-7bdfb63c135245d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5b'></a>\n",
    "## Task 5b - Run a baseline_model using your custom data splitter\n",
    "- Copy/Paste your baseline model code from above into the function below.  \n",
    "  - Replace the std_train_test_split() function with your new custom_train_test_split().\n",
    "    - Use the default split of 0.2.\n",
    "  - Run this revised function and answer the questions below.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dc2020042175358a7cb80bc16c6e7f0",
     "grade": true,
     "grade_id": "cell-3da8d537082beef3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73b7ba248c227765f6d541fc39bf90ef",
     "grade": false,
     "grade_id": "cell-f837ef40fcc382ee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def baseline_model_two():\n",
    "\n",
    "    df = get_sensor_data()\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(df)\n",
    "\n",
    "    # instantiate the DecisionTreeClassifier\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # fit the model on the training data with the features in features\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # score the model with X_test and the features in features\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    features = [col for col in df.columns]\n",
    "    return features, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# baseline_model_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ff0e7610bab57f615424833c3bb75ca",
     "grade": true,
     "grade_id": "cell-72944b90c520abfe",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5b - AG tests\n",
      "Task 5b - your answer:\n",
      "(['Subject_ID', 'Activity_Label', 'ECG_original_mean_1', 'ECG_original_std_2', 'ECG_original_trimmean25_3', 'ECG_original_median_4', 'ECG_original_skewness_5', 'ECG_original_kurtosis_6', 'ECG_original_max_7', 'ECG_original_min_8', 'ECG_original_prctile25_9', 'ECG_original_prctile75_10', 'ECG_original_geomean(abs)_11', 'ECG_original_harmmean_12', 'ECG_original_mad_13', 'ECG_original_baseline_14', 'ECG_RR_window_mean_15', 'ECG_RR_window_std_16', 'ECG_RR_window_trimmean25_17', 'ECG_RR_window_median_18', 'ECG_RR_window_skewness_19', 'ECG_RR_window_kurtosis_20', 'ECG_RR_window_max_21', 'ECG_RR_window_min_22', 'ECG_RR_window_prctile25_23', 'ECG_RR_window_prctile75_24', 'ECG_RR_window_geomean(abs)_25', 'ECG_RR_window_harmmean_26', 'ECG_RR_window_mad_27', 'ECG_RR_window_baseline_28', 'ECG_amplitude_RR_mean_29', 'ECG_amplitude_RR_std_30', 'ECG_amplitude_RR_trimmean25_31', 'ECG_amplitude_RR_median_32', 'ECG_amplitude_RR_skewness_33', 'ECG_amplitude_RR_kurtosis_34', 'ECG_amplitude_RR_max_35', 'ECG_amplitude_RR_min_36', 'ECG_amplitude_RR_prctile25_37', 'ECG_amplitude_RR_prctile75_38', 'ECG_amplitude_RR_geomean(abs)_39', 'ECG_amplitude_RR_harmmean_40', 'ECG_amplitude_RR_mad_41', 'ECG_amplitude_RR_baseline_42', 'ECG_HR_min_div_mean_43', 'ECG_HR_min_div_std_44', 'ECG_HR_min_div_trimmean25_45', 'ECG_HR_min_div_median_46', 'ECG_HR_min_div_skewness_47', 'ECG_HR_min_div_kurtosis_48', 'ECG_HR_min_div_max_49', 'ECG_HR_min_div_min_50', 'ECG_HR_min_div_prctile25_51', 'ECG_HR_min_div_prctile75_52', 'ECG_HR_min_div_geomean(abs)_53', 'ECG_HR_min_div_harmmean_54', 'ECG_HR_min_div_mad_55', 'ECG_HR_min_div_baseline_56', 'ECG_DBD_57', 'ECG_EI_58', 'ECG_IE_59', 'ECG_Logstd_60', 'ECG_RSAindex_61', 'ECG_M_62', 'ECG_Load_index_63', 'ECG_NN50_64', 'ECG_pNN50_65', 'ECG_Entropyaprox_66', 'ECG_hrv_mean_67', 'ECG_hrv_std_68', 'ECG_hrv_trimmean25_69', 'ECG_hrv_median_70', 'ECG_hrv_skewness_71', 'ECG_hrv_kurtosis_72', 'ECG_hrv_max_73', 'ECG_hrv_min_74', 'ECG_hrv_prctile25_75', 'ECG_hrv_prctile75_76', 'ECG_hrv_geomean(abs)_77', 'ECG_hrv_harmmean_78', 'ECG_hrv_mad_79', 'ECG_hrv_baseline_80', 'ECG_PSD_mean_81', 'ECG_PSD_std_82', 'ECG_PSD_trimmean25_83', 'ECG_PSD_median_84', 'ECG_PSD_skewness_85', 'ECG_PSD_kurtosis_86', 'ECG_PSD_max_87', 'ECG_PSD_min_88', 'ECG_PSD_prctile25_89', 'ECG_PSD_prctile75_90', 'ECG_PSD_geomean(abs)_91', 'ECG_PSD_harmmean_92', 'ECG_PSD_mad_93', 'ECG_PSD_baseline_94', 'ECG_p_VFL_mean_95', 'ECG_p_VFL_std_96', 'ECG_p_VFL_trimmean25_97', 'ECG_p_VFL_median_98', 'ECG_p_VFL_skewness_99', 'ECG_p_VFL_kurtosis_100', 'ECG_p_VFL_max_101', 'ECG_p_VFL_min_102', 'ECG_p_VFL_prctile25_103', 'ECG_p_VFL_prctile75_104', 'ECG_p_VFL_geomean(abs)_105', 'ECG_p_VFL_harmmean_106', 'ECG_p_VFL_mad_107', 'ECG_p_VFL_baseline_108', 'ECG_p_LF_mean_109', 'ECG_p_LF_std_110', 'ECG_p_LF_trimmean25_111', 'ECG_p_LF_median_112', 'ECG_p_LF_skewness_113', 'ECG_p_LF_kurtosis_114', 'ECG_p_LF_max_115', 'ECG_p_LF_min_116', 'ECG_p_LF_prctile25_117', 'ECG_p_LF_prctile75_118', 'ECG_p_LF_geomean(abs)_119', 'ECG_p_LF_harmmean_120', 'ECG_p_LF_mad_121', 'ECG_p_LF_baseline_122', 'ECG_p_MF_mean_123', 'ECG_p_MF_std_124', 'ECG_p_MF_trimmean25_125', 'ECG_p_MF_median_126', 'ECG_p_MF_skewness_127', 'ECG_p_MF_kurtosis_128', 'ECG_p_MF_max_129', 'ECG_p_MF_min_130', 'ECG_p_MF_prctile25_131', 'ECG_p_MF_prctile75_132', 'ECG_p_MF_geomean(abs)_133', 'ECG_p_MF_harmmean_134', 'ECG_p_MF_mad_135', 'ECG_p_MF_baseline_136', 'ECG_p_HF_mean_137', 'ECG_p_HF_std_138', 'ECG_p_HF_trimmean25_139', 'ECG_p_HF_median_140', 'ECG_p_HF_skewness_141', 'ECG_p_HF_kurtosis_142', 'ECG_p_HF_max_143', 'ECG_p_HF_min_144', 'ECG_p_HF_prctile25_145', 'ECG_p_HF_prctile75_146', 'ECG_p_HF_geomean(abs)_147', 'ECG_p_HF_harmmean_148', 'ECG_p_HF_mad_149', 'ECG_p_HF_baseline_150', 'ECG_p_total_LF_mean_151', 'ECG_p_total_LF_std_152', 'ECG_p_total_LF_trimmean25_153', 'ECG_p_total_LF_median_154', 'ECG_p_total_LF_skewness_155', 'ECG_p_total_LF_kurtosis_156', 'ECG_p_total_LF_max_157', 'ECG_p_total_LF_min_158', 'ECG_p_total_LF_prctile25_159', 'ECG_p_total_LF_prctile75_160', 'ECG_p_total_LF_geomean(abs)_161', 'ECG_p_total_LF_harmmean_162', 'ECG_p_total_LF_mad_163', 'ECG_p_total_LF_baseline_164', 'ECG_HF_LF_165', 'ECG_LF_HF_166', 'ECG_MF_HF_167', 'ECG_HF_TF_168', 'ECG_LF_MF_HF_169', 'ECG_CCV_LF_170', 'ECG_CCV_HF_171', 'ECG_RMSSDD_172', 'ECG_A1_DFA_173', 'ECG_A2_DFA_174', 'IT_Original_mean_175', 'IT_Original_std_176', 'IT_Original_trimmean25_177', 'IT_Original_median_178', 'IT_Original_skewness_179', 'IT_Original_kurtosis_180', 'IT_Original_max_181', 'IT_Original_min_182', 'IT_Original_prctile25_183', 'IT_Original_prctile75_184', 'IT_Original_geomean(abs)_185', 'IT_Original_harmmean_186', 'IT_Original_mad_187', 'IT_Original_baseline_188', 'IT_Original_Area_189', 'IT_LF_mean_190', 'IT_LF_std_191', 'IT_LF_trimmean25_192', 'IT_LF_median_193', 'IT_LF_skewness_194', 'IT_LF_kurtosis_195', 'IT_LF_max_196', 'IT_LF_min_197', 'IT_LF_prctile25_198', 'IT_LF_prctile75_199', 'IT_LF_geomean(abs)_200', 'IT_LF_harmmean_201', 'IT_LF_mad_202', 'IT_LF_baseline_203', 'IT_LF_Area_204', 'IT_RF_mean_205', 'IT_RF_std_206', 'IT_RF_trimmean25_207', 'IT_RF_median_208', 'IT_RF_skewness_209', 'IT_RF_kurtosis_210', 'IT_RF_max_211', 'IT_RF_min_212', 'IT_RF_prctile25_213', 'IT_RF_prctile75_214', 'IT_RF_geomean(abs)_215', 'IT_RF_harmmean_216', 'IT_RF_mad_217', 'IT_RF_baseline_218', 'IT_RF_Area_219', 'IT_BR_mean_220', 'IT_BRV_mean_221', 'IT_BRV_std_222', 'IT_BRV_trimmean25_223', 'IT_BRV_median_224', 'IT_BRV_skewness_225', 'IT_BRV_kurtosis_226', 'IT_BRV_max_227', 'IT_BRV_min_228', 'IT_BRV_prctile25_229', 'IT_BRV_prctile75_230', 'IT_BRV_geomean(abs)_231', 'IT_BRV_harmmean_232', 'IT_BRV_mad_233', 'IT_BRV_baseline_234', 'IT_PSD_mean_235', 'IT_PSD_std_236', 'IT_PSD_trimmean25_237', 'IT_PSD_median_238', 'IT_PSD_skewness_239', 'IT_PSD_kurtosis_240', 'IT_PSD_max_241', 'IT_PSD_min_242', 'IT_PSD_prctile25_243', 'IT_PSD_prctile75_244', 'IT_PSD_geomean(abs)_245', 'IT_PSD_harmmean_246', 'IT_PSD_mad_247', 'IT_PSD_baseline_248', 'IT_VLF_mean_249', 'IT_VLF_std_250', 'IT_VLF_trimmean25_251', 'IT_VLF_median_252', 'IT_VLF_skewness_253', 'IT_VLF_kurtosis_254', 'IT_VLF_max_255', 'IT_VLF_min_256', 'IT_VLF_prctile25_257', 'IT_VLF_prctile75_258', 'IT_VLF_geomean(abs)_259', 'IT_VLF_harmmean_260', 'IT_VLF_mad_261', 'IT_VLF_baseline_262', 'IT_LF_mean_263', 'IT_LF_std_264', 'IT_LF_trimmean25_265', 'IT_LF_median_266', 'IT_LF_skewness_267', 'IT_LF_kurtosis_268', 'IT_LF_max_269', 'IT_LF_min_270', 'IT_LF_prctile25_271', 'IT_LF_prctile75_272', 'IT_LF_geomean(abs)_273', 'IT_LF_harmmean_274', 'IT_LF_mad_275', 'IT_LF_baseline_276', 'IT_MF_mean_277', 'IT_MF_std_278', 'IT_MF_trimmean25_279', 'IT_MF_median_280', 'IT_MF_skewness_281', 'IT_MF_kurtosis_282', 'IT_MF_max_283', 'IT_MF_min_284', 'IT_MF_prctile25_285', 'IT_MF_prctile75_286', 'IT_MF_geomean(abs)_287', 'IT_MF_harmmean_288', 'IT_MF_mad_289', 'IT_MF_baseline_290', 'IT_HF_mean_291', 'IT_HF_std_292', 'IT_HF_trimmean25_293', 'IT_HF_median_294', 'IT_HF_skewness_295', 'IT_HF_kurtosis_296', 'IT_HF_max_297', 'IT_HF_min_298', 'IT_HF_prctile25_299', 'IT_HF_prctile75_300', 'IT_HF_geomean(abs)_301', 'IT_HF_harmmean_302', 'IT_HF_mad_303', 'IT_HF_baseline_304', 'IT_p_Total_mean_305', 'IT_p_Total_std_306', 'IT_p_Total_trimmean25_307', 'IT_p_Total_median_308', 'IT_p_Total_skewness_309', 'IT_p_Total_kurtosis_310', 'IT_p_Total_max_311', 'IT_p_Total_min_312', 'IT_p_Total_prctile25_313', 'IT_p_Total_prctile75_314', 'IT_p_Total_geomean(abs)_315', 'IT_p_Total_harmmean_316', 'IT_p_Total_mad_317', 'IT_p_Total_baseline_318', 'IT_HF_LF_319', 'IT_LF_HF_320', 'IT_MF_HF_321', 'IT_HF_TF_322', 'IT_LF_MF_HF_323', 'IT_CCV_LF_324', 'IT_CCV_HF_325', 'EDA_Original_mean_326', 'EDA_Original_std_327', 'EDA_Original_trimmean25_328', 'EDA_Original_median_329', 'EDA_Original_skewness_330', 'EDA_Original_kurtosis_331', 'EDA_Original_max_332', 'EDA_Original_min_333', 'EDA_Original_prctile25_334', 'EDA_Original_prctile75_335', 'EDA_Original_geomean(abs)_336', 'EDA_Original_harmmean_337', 'EDA_Original_mad_338', 'EDA_Original_baseline_339', 'EDA_processed_mean_340', 'EDA_processed_std_341', 'EDA_processed_trimmean25_342', 'EDA_processed_median_343', 'EDA_processed_skewness_344', 'EDA_processed_kurtosis_345', 'EDA_processed_max_346', 'EDA_processed_min_347', 'EDA_processed_prctile25_348', 'EDA_processed_prctile75_349', 'EDA_processed_geomean(abs)_350', 'EDA_processed_harmmean_351', 'EDA_processed_mad_352', 'EDA_processed_baseline_353', 'EDA_Filt1_mean_354', 'EDA_Filt1_std_355', 'EDA_Filt1_trimmean25_356', 'EDA_Filt1_median_357', 'EDA_Filt1_skewness_358', 'EDA_Filt1_kurtosis_359', 'EDA_Filt1_max_360', 'EDA_Filt1_min_361', 'EDA_Filt1_prctile25_362', 'EDA_Filt1_prctile75_363', 'EDA_Filt1_geomean(abs)_364', 'EDA_Filt1_harmmean_365', 'EDA_Filt1_mad_366', 'EDA_Filt1_baseline_367', 'EDA_Filt2_mean_368', 'EDA_Filt2_std_369', 'EDA_Filt2_trimmean25_370', 'EDA_Filt2_median_371', 'EDA_Filt2_skewness_372', 'EDA_Filt2_kurtosis_373', 'EDA_Filt2_max_374', 'EDA_Filt2_min_375', 'EDA_Filt2_prctile25_376', 'EDA_Filt2_prctile75_377', 'EDA_Filt2_geomean(abs)_378', 'EDA_Filt2_harmmean_379', 'EDA_Filt2_mad_380', 'EDA_Filt2_baseline_381', 'EDA_cross_pos_382', 'EDA_cross_neg_383', 'EDA_n_ocu_384', 'EDA_amp_scr_385', 'EDA_p_samples_386', 'EDA_area_387', 'EDA_Functionals_power_Originalmean_388', 'EDA_Functionals_power_Originalstd_389', 'EDA_Functionals_power_Originaltrimmean25_390', 'EDA_Functionals_power_Originalmedian_391', 'EDA_Functionals_power_Originalskewness_392', 'EDA_Functionals_power_Originalkurtosis_393', 'EDA_Functionals_power_Originalmax_394', 'EDA_Functionals_power_Originalmin_395', 'EDA_Functionals_power_Originalprctile25_396', 'EDA_Functionals_power_Originalprctile75_397', 'EDA_Functionals_power_Originalgeomean(abs)_398', 'EDA_Functionals_power_Originalharmmean_399', 'EDA_Functionals_power_Originalmad_400', 'EDA_Functionals_power_Originalbaseline_401', 'EDA_Functionals_power_Fil12mean_402', 'EDA_Functionals_power_Fil12std_403', 'EDA_Functionals_power_Fil12trimmean25_404', 'EDA_Functionals_power_Fil12median_405', 'EDA_Functionals_power_Fil12skewness_406', 'EDA_Functionals_power_Fil12kurtosis_407', 'EDA_Functionals_power_Fil12max_408', 'EDA_Functionals_power_Fil12min_409', 'EDA_Functionals_power_Fil12prctile25_410', 'EDA_Functionals_power_Fil12prctile75_411', 'EDA_Functionals_power_Fil12geomean(abs)_412', 'EDA_Functionals_power_Fil12harmmean_413', 'EDA_Functionals_power_Fil12mad_414', 'EDA_Functionals_power_Fil12baseline_415', 'EDA_Functionals_power_Filt2mean_416', 'EDA_Functionals_power_Filt2std_417', 'EDA_Functionals_power_Filt2trimmean25_418', 'EDA_Functionals_power_Filt2median_419', 'EDA_Functionals_power_Filt2skewness_420', 'EDA_Functionals_power_Filt2kurtosis_421', 'EDA_Functionals_power_Filt2max_422', 'EDA_Functionals_power_Filt2min_423', 'EDA_Functionals_power_Filt2prctile25_424', 'EDA_Functionals_power_Filt2prctile75_425', 'EDA_Functionals_power_Filt2geomean(abs)_426', 'EDA_Functionals_power_Filt2harmmean_427', 'EDA_Functionals_power_Filt2mad_428', 'EDA_Functionals_power_Filt2baseline_429', 'EDA_Original_mean_430', 'EDA_Original_std_431', 'EDA_Original_trimmean25_432', 'EDA_Original_median_433', 'EDA_Original_skewness_434', 'EDA_Original_kurtosis_435', 'EDA_Original_max_436', 'EDA_Original_min_437', 'EDA_Original_prctile25_438', 'EDA_Original_prctile75_439', 'EDA_Original_geomean(abs)_440', 'EDA_Original_harmmean_441', 'EDA_Original_mad_442', 'EDA_Original_baseline_443', 'EDA_processed_mean_444', 'EDA_processed_std_445', 'EDA_processed_trimmean25_446', 'EDA_processed_median_447', 'EDA_processed_skewness_448', 'EDA_processed_kurtosis_449', 'EDA_processed_max_450', 'EDA_processed_min_451', 'EDA_processed_prctile25_452', 'EDA_processed_prctile75_453', 'EDA_processed_geomean(abs)_454', 'EDA_processed_harmmean_455', 'EDA_processed_mad_456', 'EDA_processed_baseline_457', 'EDA_Filt1_mean_458', 'EDA_Filt1_std_459', 'EDA_Filt1_trimmean25_460', 'EDA_Filt1_median_461', 'EDA_Filt1_skewness_462', 'EDA_Filt1_kurtosis_463', 'EDA_Filt1_max_464', 'EDA_Filt1_min_465', 'EDA_Filt1_prctile25_466', 'EDA_Filt1_prctile75_467', 'EDA_Filt1_geomean(abs)_468', 'EDA_Filt1_harmmean_469', 'EDA_Filt1_mad_470', 'EDA_Filt1_baseline_471', 'EDA_Filt2_mean_472', 'EDA_Filt2_std_473', 'EDA_Filt2_trimmean25_474', 'EDA_Filt2_median_475', 'EDA_Filt2_skewness_476', 'EDA_Filt2_kurtosis_477', 'EDA_Filt2_max_478', 'EDA_Filt2_min_479', 'EDA_Filt2_prctile25_480', 'EDA_Filt2_prctile75_481', 'EDA_Filt2_geomean(abs)_482', 'EDA_Filt2_harmmean_483', 'EDA_Filt2_mad_484', 'EDA_Filt2_baseline_485', 'EDA_cross_pos_486', 'EDA_cross_neg_487', 'EDA_n_ocu_488', 'EDA_amp_scr_489', 'EDA_p_samples_490', 'EDA_area_491', 'EDA_Functionals_power_Originalmean_492', 'EDA_Functionals_power_Originalstd_493', 'EDA_Functionals_power_Originaltrimmean25_494', 'EDA_Functionals_power_Originalmedian_495', 'EDA_Functionals_power_Originalskewness_496', 'EDA_Functionals_power_Originalkurtosis_497', 'EDA_Functionals_power_Originalmax_498', 'EDA_Functionals_power_Originalmin_499', 'EDA_Functionals_power_Originalprctile25_500', 'EDA_Functionals_power_Originalprctile75_501', 'EDA_Functionals_power_Originalgeomean(abs)_502', 'EDA_Functionals_power_Originalharmmean_503', 'EDA_Functionals_power_Originalmad_504', 'EDA_Functionals_power_Originalbaseline_505', 'EDA_Functionals_power_Fil12mean_506', 'EDA_Functionals_power_Fil12std_507', 'EDA_Functionals_power_Fil12trimmean25_508', 'EDA_Functionals_power_Fil12median_509', 'EDA_Functionals_power_Fil12skewness_510', 'EDA_Functionals_power_Fil12kurtosis_511', 'EDA_Functionals_power_Fil12max_512', 'EDA_Functionals_power_Fil12min_513', 'EDA_Functionals_power_Fil12prctile25_514', 'EDA_Functionals_power_Fil12prctile75_515', 'EDA_Functionals_power_Fil12geomean(abs)_516', 'EDA_Functionals_power_Fil12harmmean_517', 'EDA_Functionals_power_Fil12mad_518', 'EDA_Functionals_power_Fil12baseline_519', 'EDA_Functionals_power_Filt2mean_520', 'EDA_Functionals_power_Filt2std_521', 'EDA_Functionals_power_Filt2trimmean25_522', 'EDA_Functionals_power_Filt2median_523', 'EDA_Functionals_power_Filt2skewness_524', 'EDA_Functionals_power_Filt2kurtosis_525', 'EDA_Functionals_power_Filt2max_526', 'EDA_Functionals_power_Filt2min_527', 'EDA_Functionals_power_Filt2prctile25_528', 'EDA_Functionals_power_Filt2prctile75_529', 'EDA_Functionals_power_Filt2geomean(abs)_530', 'EDA_Functionals_power_Filt2harmmean_531', 'EDA_Functionals_power_Filt2mad_532', 'EDA_Functionals_power_Filt2baseline_533'], 0.8314732142857143)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = baseline_model_two()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Task 5b: Your function should return a tuple.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[0], list\n",
    "), \"Task 5b: Tuple element zero should be a list object.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 5b: Tuple element one should be a np.float64 value.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b81f5a7173db01fec2ef9bf8926c527",
     "grade": false,
     "grade_id": "cell-21809bc2608e0994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t5c'></a>\n",
    "## Task 5c - Custom train/test split questions (2 Points).\n",
    "\n",
    "1. Is the score of the model that incorporates custom_train_test_split() significantly different from the std_train_test_split() version?  \n",
    "2. What issue(s) have we eliminated with our new custom_train_test_split() function?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c97c9a253e5e8eec91e31911e863cd57",
     "grade": true,
     "grade_id": "cell-175bb32a2a2293c4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. uhhh no, it's not. the scores are identical\n",
    "2. i'm not exactly sure what we've fixed since the scores are identical. so i put the desired features in the custom tts function so we don't to repeat that every time. however, i could have easily done that with the standard sklearn implementation too... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "100121314bbd7477eb138872a8ea2439",
     "grade": false,
     "grade_id": "cell-2e0f6b0e6c8930f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t6'></a>\n",
    "## Task 6 - Confusion Matrix (5 Points).\n",
    "\n",
    " - We now want to better understand the relationship of correct and incorrect predictons made by a classification model. A very useful tool for examining a multiclass outcome, such as we have with our sensor dataset, is the [Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    " - Using the SciKit-Learn [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) model, create a function that returns a Confusion Matrix.\n",
    "   - Your function should accept zero arguments.  \n",
    "   - Set hyperparameter: max_iter=1000\n",
    "   - Any random_state or seed values should be initialized with an integer value of 42.\n",
    " - Use your previously defined functions to derive your train and test sets.\n",
    " - Scaling is an important factor in many Machine Learning projects (See section 3.3 in the course textbook). For the current dataset, use the sklearn method StandardScaler() to scale the train and test sets.\n",
    " - Using code that you had previously developed, include all features who's name includes the substring defined in \n",
    "**base_feature_selector** ([library imports](#library-imports)).\n",
    "- Your function should return the following tuple:  \n",
    "   - The confusion matrix array as returned by the sklean method confusion_matrix().  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "889f01ae32fe15408e098823a77c9623",
     "grade": true,
     "grade_id": "cell-31043e0e4351d70e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a012cb704df6542e0f0fc22bbd1a833e",
     "grade": false,
     "grade_id": "cell-02b6f1ff73a7c6a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def LR_confusion_matrix():\n",
    "    df = get_sensor_data()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(df)\n",
    "\n",
    "    # instantiate the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fit the scaler on the training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # transform the training data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    # transform the test data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # instantiate the LogisticRegression\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    # fit the model on the training data with the features in features\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # score the model with X_test and the features in features\n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "    # predict the labels for the test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # create the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# LR_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c48dcf1305089a7949ec4b53648e30ad",
     "grade": true,
     "grade_id": "cell-9ce7903f9c06f5f5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6 - AG tests\n",
      "Task 6 - your answer:\n",
      "[[152  41  29   2]\n",
      " [  0 120  80  14]\n",
      " [  2  76 132  18]\n",
      " [  1  18  24 187]]\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = LR_confusion_matrix()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans, np.ndarray\n",
    "), \"Task 6: The second tuple element should be an np.ndarray\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef11b7c4d3fae4bfdde4f5936c08cf03",
     "grade": false,
     "grade_id": "cell-4c32db5c2bff0137",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='vcm'></a>\n",
    "## Visualizing the Confusion Matrix\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8e666ad0ca9607d5bf7f7e7f59d246b",
     "grade": false,
     "grade_id": "cell-740465ee9e481736",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion():\n",
    "    cm = LR_confusion_matrix()\n",
    "    labels = {\"neutral\": 1, \"emotional\": 2, \"mental\": 3, \"physical\": 4}.keys()\n",
    "    display_cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    display_cm.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# plot_confusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12a957b449585b003807a0e6e5f0eb14",
     "grade": false,
     "grade_id": "cell-3a8431087ad8d20c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<a id='t7'></a>\n",
    "## Task 7 - Basic Confusion Matrix Understanding (5 Points).\n",
    "\n",
    " - Answer the following questions concerning the above Confusion Matrix.  \n",
    " - Record (hardcode) your answers in the answer variables in the cell below for autograding purposes.  \n",
    " - Your answers should use the Python types **int**, **float**, or **str** as appropriate.\n",
    " \n",
    "Q1. What is the number of __Correctly Predicted__ for the _mental_ activity?  \n",
    "Q2. How many __False Positive__ predictions were made for the _neutral_ activity?  \n",
    "Q3. How many __False Negative__ predictions were made for the _physical_ activity?  \n",
    "Q4. What is the __Precision__ Score for the _mental_ activity? (round to three decimal places)  \n",
    "Q5. What is the __Recall__ Score for the _emotional_ activity? (round to three decimal places)  \n",
    "Q6. What is the overall __Accuracy__ for the current model? (round to three decimal places)  \n",
    "Q7. Which activity is most confused for _mental_ activity when not?  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fab445f7002d62016b0483847a49d2a2",
     "grade": true,
     "grade_id": "cell-0a69762d0a229166",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98503243f5c05907a8b5b172aaf3ea60",
     "grade": false,
     "grade_id": "cell-aa8a1e16f3e1108a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Supply your answers to Q1 through Q7\n",
    "# in variables a1 through a7.\n",
    "\n",
    "def confusion_matrix_questions():\n",
    "\n",
    "    a1 = 132\n",
    "    a2 = 2+1\n",
    "    a3 = 1+18+24\n",
    "    fp = 29+80+24\n",
    "    a4 = round(132/(132+fp), 3) #prec=TP / (TP + FP) tp=132\n",
    "    fn = 80+14\n",
    "    a5 = round(120/(120+fn), 3) #rec=TP / (TP + FN) tp=120\n",
    "    num = 152+120+132+187\n",
    "    dem = LR_confusion_matrix().sum()\n",
    "    a6 = round(num/dem, 3) #acc=(TP+TN) / (TP+TN+FP+FN)\n",
    "    a7 = 'emotional'\n",
    "\n",
    "    return (a1, a2, a3, a4, a5, a6, a7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "991d7f9808520d524f91af303c5d6b46",
     "grade": true,
     "grade_id": "cell-6c520b1fae9d0a50",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 7 - AG tests\n",
      "Task 7 - your answer:\n",
      "(132, 3, 43, 0.498, 0.561, 0.66, 'emotional')\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = confusion_matrix_questions()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 7\n",
    "), \"Task 7: Your answer tuple does not contain the correct number of answers.\"\n",
    "assert isinstance(stu_ans[0], int), \"Task 7: Answer one should be an integer\"\n",
    "assert isinstance(stu_ans[1], int), \"Task 7: Answer two should be an integer\"\n",
    "assert isinstance(stu_ans[2], int), \"Task 7: Answer three should be an integer\"\n",
    "assert isinstance(stu_ans[3], float), \"Task 7: Answer four should be a float\"\n",
    "assert isinstance(stu_ans[4], float), \"Task 7: Answer five should be a float\"\n",
    "assert isinstance(stu_ans[5], float), \"Task 7: Answer six should be a float\"\n",
    "assert isinstance(stu_ans[6], str), \"Task 7: Answer seven should be a string\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b77416d3cbdbf0726f6d02d69c434766",
     "grade": false,
     "grade_id": "cell-1aeefba857843791",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t8'></a>\n",
    "## Task 8 - Feature Importance, part 1 (5 Points).\n",
    "#### Now we want to explore how some models are able to provide additional insight into the features that played a prominent role in the estimation outcome.\n",
    " - Produce a function that implements a RandomForestClassifier model, which includes the [**feature_importances_**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_) attribute.\n",
    "- The function accepts a single argument for the top X number of features, the default value will be 10.\n",
    "  - The classifier should use only two parameters:\n",
    "    - random_state=42\n",
    "    - n_jobs=-1\n",
    "- Use your previously defined functions to derive your train and test sets.\n",
    "- Using code that you had previously developed, include all features who's name includes the substring defined by **base_feature_selector** ([library imports](#library-imports)).\n",
    " - The function should return a tuple of two elements.\n",
    "   - The first element will be a **sorted** list of tuples in the form **\\[('feature_name', importance_value),...\\]**. The list of tuples should be sorted in descending order.\n",
    "     - This list of tuples should be sorted in **descending order** of feature_importance.\n",
    "   - The second element (test data score) should be an np.float64 value.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c296f586bf90361275af27ae360a7e16",
     "grade": true,
     "grade_id": "cell-74def7d945e536be",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3235be835faf0804ca3bf3a2699dab4",
     "grade": false,
     "grade_id": "cell-ffe4926e6361f5fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_top_features(top=10):\n",
    "    df = get_sensor_data()\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(df)\n",
    "\n",
    "    # instantiate the RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    # fit the model on the training data with the features in features\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # score the model with X_test and the features in features\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    # get the feature importances\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # get the indices of the top features\n",
    "    top_indices = np.argsort(importances)[-top:]\n",
    "    \n",
    "    # get the names of the top features\n",
    "    top_features = [X_train.columns[i] for i in top_indices]\n",
    "    \n",
    "    return sorted(list(zip(top_features, importances)), key=lambda x: -x[1]), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# get_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33997807dc9ed420c60c46bb6e41404f",
     "grade": true,
     "grade_id": "cell-b112a369a5bef4a9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 8 - AG tests\n",
      "Task 8 - your answer:\n",
      "([('IT_PSD_mad_247', 0.06284654868820433), ('ECG_HR_min_div_mad_55', 0.055503545631525826), ('IT_p_Total_mad_317', 0.03952694002284685), ('ECG_RR_window_mad_27', 0.03894278037219378), ('ECG_amplitude_RR_mad_41', 0.023886291465430916), ('EDA_processed_mad_456', 0.019413286793435968), ('IT_Original_mad_187', 0.014245031593808254), ('ECG_original_mad_13', 0.013855755547695867), ('IT_LF_mad_202', 0.01321965918048359), ('IT_RF_mad_217', 0.012913507192355577)], 0.8794642857142857)\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = get_top_features()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == 2\n",
    "), \"Task 8: Your answer tuple does not contain the correct number of elements.\"\n",
    "\n",
    "assert isinstance(stu_ans[0], list), \"Task 9: The first tuple element should be a list\"\n",
    "\n",
    "assert (\n",
    "    len(stu_ans[0]) == 10\n",
    "), \"Task 9: The default number of top features is not correct.\"\n",
    "\n",
    "assert isinstance(\n",
    "    stu_ans[1], np.float64\n",
    "), \"Task 9: get_top_features() second return element should be an np.float64.\"\n",
    "\n",
    "del stu_ans\n",
    "\n",
    "# Some hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a70c8c9fddfba76b593c63a57326abc1",
     "grade": false,
     "grade_id": "cell-0562af8e13d94e4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t9'></a>\n",
    "## Task 9 - Feature Importance, part 2 (10 Points).\n",
    "\n",
    "#### The value of Feature Importance \n",
    "- This follow-on task will use the same **RandomForestClassifier** model as in your get_top_features() function.\n",
    "- The new model will use a portion of the output returned by the get_top_features() function.\n",
    "- Use the previously defined functions to derive your train and test datasets.\n",
    "- Create a loop that trains your model with an incrementally increasing number of features from the top features list.\n",
    "  - The first pass will include the topmost important feature, the second pass will include the top two most important features and so on until the final pass of all top X features.\n",
    "- Your function should return a list of feature-based test data scores produced by the model.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5153385992ff7bd1228d9a5635c03f1",
     "grade": true,
     "grade_id": "cell-f85b4f97ca14b2b6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c60dd666af9160639df3e8dfbb0461e2",
     "grade": false,
     "grade_id": "cell-61533567ca475486",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_top_features(top=10):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(get_sensor_data())\n",
    "    features, score = get_top_features(top)\n",
    "\n",
    "    feature_names = [f[0] for f in features]\n",
    "\n",
    "    # loop that trains your model the top features incrementally from 1 to top\n",
    "    # and scores the model on the test data. return scores as list produced by RandomForestClassifier.score()\n",
    "    scores = []\n",
    "    for i in range(1, top+1):\n",
    "        model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train[feature_names[:i]], y_train)\n",
    "        scores.append(model.score(X_test[feature_names[:i]], y_test))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# score_top_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06177e994c63dd06acd34152b9520e0b",
     "grade": true,
     "grade_id": "cell-bbade458d0c15e25",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - AG tests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - your answer:\n",
      "[0.41629464285714285, 0.48660714285714285, 0.48660714285714285, 0.6618303571428571, 0.7544642857142857, 0.7991071428571429, 0.8616071428571429, 0.8973214285714286, 0.890625, 0.890625]\n"
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "top = 10\n",
    "stu_ans = score_top_features(top)\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "assert (\n",
    "    len(stu_ans) == top\n",
    "), \"Task 9: Your function does not return the correct number of scores.\"\n",
    "\n",
    "assert all(\n",
    "    isinstance(x, np.float64) for x in stu_ans\n",
    "), \"Task 9: One or more of the returned scores is of an incorrect type.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71dfe7a3b12c5d5bc18546340f41e1fc",
     "grade": false,
     "grade_id": "cell-394cc694e2554086",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='scoresplot'></a>\n",
    "## Scores Plot\n",
    "The plot_scores() function accepts top X features argumnet which defaults to a value of 10. Feel free to change the argument to better see how accuracy is affected by the number of top features used to train the model.  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "149bc8e99b66731b538ec3f9641b9f10",
     "grade": false,
     "grade_id": "cell-8fe2a304ac06b8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_scores(top=10):\n",
    "\n",
    "    if top > 29:\n",
    "        top = 29\n",
    "\n",
    "    top_x_features, score = get_top_features(top)\n",
    "    scores = score_top_features(top)\n",
    "\n",
    "    importance_scores = [score[1] for score in top_x_features]\n",
    "    x_axis = np.arange(1, len(scores) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.xticks(x_axis)\n",
    "    plt.ylim([0, max(score, max(importance_scores)) + 0.05])\n",
    "    plt.xlabel(\"Number of Top 10 Features Used\")\n",
    "    plt.ylabel(\"Score Value\")\n",
    "    plt.grid(alpha=0.25)\n",
    "\n",
    "    plt.plot(x_axis, scores, label=\"Accuracy Score\", c=\"g\", linestyle=\"solid\")\n",
    "\n",
    "    plt.plot(\n",
    "        x_axis,\n",
    "        importance_scores,\n",
    "        label=\"Feature Importance Scores\",\n",
    "        c=\"r\",\n",
    "        linestyle=\"solid\",\n",
    "    )\n",
    "\n",
    "    plt.axhline(\n",
    "        score,\n",
    "        label=f\"All '{base_feature_selector}' features score\",\n",
    "        c=\"b\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs feature importance\n",
    "# the plot_scores() function accepts an optional top N parameter.\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b37a65c6c13fd22b71a9f4b58df0ebff",
     "grade": false,
     "grade_id": "cell-4e84ab0e7aaf6f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='t10'></a>\n",
    "## Task 10 - Final project (50 Points).\n",
    "\n",
    "- The final task for this assignment is open-ended with only a few **constraints**. Using any of the Supervised Machine Learning techniques and models presented in this course, produce a model that produces a best-possible ROC-AUC score. Your Task 10 award points will be evaluated solely on this score. The primary constraint for this task is that you will be able to utilize not more than **10** of the 533 available data features in the training and scoring of your model. A quick calculation of the number of available combinations C(n, r) = C(533, 10) = $\\frac{n!}{r!(n-r)!}$ = 4.684e20. That is very large number of possible combinations (the number of permutations is even greater)! Because of the intractability of checking all possible 10-feature combinations, it will be necessary to devise a scheme whereby your algorithm makes a selection of features and scores that selection. Be creative but also efficient in your feature selection process; this may well mean computational efficiency. Attempting to examine too many features at one time can be computationally very expensive! Because multiple feature selection cycles may be necessary, you will also need to develop an efficient method of keeping track of the top model, features, and score.  \n",
    "\n",
    "- Why would we want to limit the number of features? \n",
    "   1. The creator of the project may want to minimize the number of sensors/measurements required to move the project forward.\n",
    "   2. The final product will be used on a smartphone where resource consumption is always a concern.\n",
    "   3. Computational resource availability of the development environment could be constrained due to budget availability.\n",
    "   4. The development environment may be intentionally constrained to mimic the production environment.\n",
    "  \n",
    "- You will find that even with these limitations, some model choices will still consume significant resources, even to the point of crashing the Python kernel!  \n",
    "\n",
    "- The activity_model() function:\n",
    "  - Arguments: none\n",
    "  - Use your previously defined functions to derive your train and test sets.\n",
    "  - If feasible, expand upon your previously created feature selection code.\n",
    "  - Use the following parameters when establishing your [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) method:\n",
    "    - average=\"macro\"\n",
    "    - multi_class=\"ovr\"\n",
    "  - return: a tuple consisting of (fit_model, feature_list, roc_auc_score)  \n",
    "\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e9807495e332a7cc98a573fd27cb34",
     "grade": true,
     "grade_id": "cell-25d9f52ee1c53c77",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden autograder codeblock\n",
    "task_id = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d13d8ecd713b4ed9d58940ec96042792",
     "grade": false,
     "grade_id": "cell-aa54eef9e0c09556",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def activity_model():\n",
    "    df = get_sensor_data()\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(df)\n",
    "\n",
    "    features, score = get_top_features(8)\n",
    "    feature_names = [f[0] for f in features]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train[feature_names], y_train)\n",
    "    \n",
    "    #predict the probabilities of the test data\n",
    "    y_pred = model.predict_proba(X_test[feature_names])\n",
    "\n",
    "    # get the roc-auc score\n",
    "    score = roc_auc_score(y_test, y_pred, average='macro', multi_class='ovr')\n",
    "    return model, feature_names, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore your solution\n",
    "# Remember to comment the following function call before submitting the notebook.\n",
    "\n",
    "# activity_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='t10ag'></a>\n",
    "## Task 10 Autograder Scoring\n",
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f18f6f816490cdef3c7a628c8f00678b",
     "grade": true,
     "grade_id": "cell-b75d744376ca0a86",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 10 - AG tests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 10 - your answer:\n",
      "(RandomForestClassifier(n_jobs=-1, random_state=42), ['ECG_HR_min_div_mad_55', 'EDA_processed_mad_456', 'ECG_RR_window_mad_27', 'ECG_amplitude_RR_mad_41', 'IT_RF_mad_217', 'ECG_original_mad_13', 'IT_LF_mad_202', 'IT_Original_mad_187'], 0.9610249666000729)\n"
     ]
    }
   ],
   "source": [
    "# Hidden autograder model validation\n",
    "# test for AUC score >= 0.83\n",
    "\n",
    "print(f\"Task {task_id} - AG tests\")\n",
    "stu_ans = activity_model()\n",
    "\n",
    "print(f\"Task {task_id} - your answer:\\n{stu_ans}\")\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.83\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.83. You will not receive any points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a8a650f365fb75e4b394750f061a15f",
     "grade": true,
     "grade_id": "cell-51c43ad464c6a07b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.85\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.85\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.85. You will receive 25 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65265237510370aab9f17f05ca174c41",
     "grade": true,
     "grade_id": "cell-8013377ff7931f48",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.87\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.87\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.87. You will receive 30 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93cd28cd440d1f6ab2b2e4de33f5f63f",
     "grade": true,
     "grade_id": "cell-ebe32e8d5f5255f4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.89\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.89\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.89. You will receive 35 points for this task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ad18ab63b716f46b31afae3e89d8b60",
     "grade": true,
     "grade_id": "cell-ee59bccdda8ea14c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# autograder test - AUC >= 0.91\n",
    "\n",
    "\n",
    "assert (\n",
    "    stu_ans[2] >= 0.91\n",
    "), f\"Task 10: Your test AUC {stu_ans[2]:.4f} is less than 0.91. You will receive 45 points for this task.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#toc'>TOC</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v2_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

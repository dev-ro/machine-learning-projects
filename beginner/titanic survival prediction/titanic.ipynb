{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset\n",
    "\n",
    "The goal is to predict whether a passenger survived the Titanic using binary classification\n",
    "\n",
    "### Step 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the training data\n",
    "df_train = pd.read_csv('assets/train.csv')\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv('assets/test.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the ticket column as it's not likely to contain any useful information\n",
    "df_train.drop('Ticket', axis=1, inplace=True)\n",
    "df_test.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the training data loaded. The train.csv file contains the details of a subset of the passengers on board the Titanic, along with a Survived column indicating whether each passenger survived the disaster.\n",
    "\n",
    "### Now, let's explore the data and understand each column:\n",
    "\n",
    "**PassengerId**: Unique ID assigned to each passenger.\n",
    "\n",
    "**Survived**: This is our target variable which we're trying to predict. It's a binary variable where '1' indicates that the passenger survived and '0' indicates that they did not.\n",
    "\n",
    "**Pclass**: This is the ticket class and can be seen as a proxy for socio-economic status. It's a categorical variable with '1' for 1st class, '2' for 2nd class, and '3' for 3rd class.\n",
    "\n",
    "**Name**: The name of the passenger.\n",
    "\n",
    "**Sex**: The gender of the passenger, either 'male' or 'female'.\n",
    "\n",
    "**Age**: The age of the passenger.\n",
    "\n",
    "**SibSp**: This indicates the number of siblings or spouses the passenger had aboard the Titanic.\n",
    "\n",
    "**Parch**: This indicates the number of parents or children the passenger had aboard the Titanic.\n",
    "\n",
    "**Ticket**: The ticket number of the passenger.\n",
    "\n",
    "**Fare**: How much the passenger paid for the ticket.\n",
    "\n",
    "**Cabin**: The cabin number where the passenger stayed.\n",
    "\n",
    "**Embarked**: The port where the passenger embarked. It's a categorical variable with 'C' for Cherbourg, 'Q' for Queenstown, and 'S' for Southampton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick overview of the dataset\n",
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This output gives us some important information about the structure of the dataset:\n",
    "\n",
    "**Missing Values**: The Age, Cabin, and Embarked columns have missing values. For Age, we might want to fill in missing values using an approach that makes sense given the distribution and nature of the data, like using median age. Cabin has a large number of missing values (687 out of 891), and might not add much value to our predictions. It could be dropped or engineered into a simpler feature like \"Cabin Known: Yes/No\". For Embarked, as there are only two missing values, we could fill in with the most common embarkation point.\n",
    "\n",
    "**Data Types**: There are three kinds of data types in our dataset: integers (int64), floats (float64), and objects. Object usually means that the data type is string, but it might also be used for other data types that pandas doesn't recognize. We will need to encode the categorical variables (Sex, Embarked) into numerical ones, as machine learning algorithms work with numerical data. The Name and Ticket columns may require special treatment or might be dropped, depending on whether we think they'll be useful.\n",
    "\n",
    "**Number of Entries**: All columns have 891 entries except for the ones with missing values. This consistency is important, otherwise we would need to investigate why there are mismatches.\n",
    "\n",
    "**Potential Feature Engineering**: SibSp and Parch represent the number of siblings/spouses and parents/children aboard. We might create a new feature called FamilySize by adding these two together + 1 (the passenger themself).\n",
    "\n",
    "With this information, we can move on to the next steps of data cleaning and feature engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data cleaning and feature engineering steps, we want to make sure our data is in a form that's amenable to the kind of analysis we want to perform. This involves handling missing data, dealing with outliers, encoding categorical variables, and potentially creating new features that might give us more predictive power.\n",
    "\n",
    "Here are some steps we can follow:\n",
    "\n",
    "### 1. **Dealing with Missing Data**\n",
    "\n",
    "a. **Age**: This column has 177 missing values. We could fill the missing values with the median age. The median is often a better choice than the mean for data with outliers, which age might have (very young and very old passengers).\n",
    "\n",
    "b. **Cabin**: This column has a lot of missing values (687 out of 891). Since there's so much missing, it might not be very useful in its current form. We could transform this column into a binary one: known (1) or unknown (0).\n",
    "\n",
    "c. **Embarked**: There are only 2 missing values. We could fill in these values with the most common embarkation point.\n",
    "\n",
    "### 2. **Encoding Categorical Variables**\n",
    "\n",
    "a. **Sex**: This is a binary categorical variable. It could be encoded as 0 (male) and 1 (female).\n",
    "\n",
    "b. **Embarked**: This is a multi-class categorical variable. One-hot encoding can be used here to convert each category value into a new column and assigns a 1 or 0 (True/False) value to the column.\n",
    "\n",
    "### 3. **Feature Engineering**\n",
    "\n",
    "a. **Name**: We can extract titles (Mr, Mrs, Miss, etc) from the name, which might give us additional information about the passenger's social status that could be informative.\n",
    "\n",
    "b. **FamilySize**: We can create a new feature called FamilySize that is the sum of SibSp and Parch plus one (the passenger themself).\n",
    "\n",
    "c. **IsAlone**: A binary feature indicating if the passenger is alone. It could be derived from FamilySize.\n",
    "\n",
    "d. **FareBin and AgeBin**: It can be useful to transform continuous variables into categorical ones. We can create categorical bins for Fare and Age.\n",
    "\n",
    "e. **Ticket**: The ticket column might be dropped, as it is unlikely to contain useful information. The exception would be if there are shared ticket numbers among passengers (which might indicate groups travelling together), but this would require additional exploration.\n",
    "\n",
    "Remember, these are general suggestions and might need to be adapted based on the specifics of the dataset and the results of exploratory data analysis. All changes should be motivated by a solid understanding of the data and the problem we're trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of the 'Age' column\n",
    "median_age = df_train['Age'].median()\n",
    "median_age = df_test['Age'].median()\n",
    "\n",
    "# Fill the missing values in the 'Age' column with the median value\n",
    "df_train['Age'].fillna(median_age, inplace=True)\n",
    "df_test['Age'].fillna(median_age, inplace=True)\n",
    "\n",
    "# Transform 'Cabin' column to 'Known' (1) if a cabin is assigned, and 'Unknown' (0) otherwise\n",
    "df_train['Cabin'] = df_train['Cabin'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "df_test['Cabin'] = df_test['Cabin'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "# Fill the missing values in 'Embarked' column with the most common port\n",
    "most_common_port = df_train['Embarked'].mode()[0]\n",
    "most_common_port = df_test['Embarked'].mode()[0]\n",
    "df_train['Embarked'].fillna(most_common_port, inplace=True)\n",
    "df_test['Embarked'].fillna(most_common_port, inplace=True)\n",
    "\n",
    "# Convert Embarked to new columns Embarked_C, Embarked_Q and Embarked_S and assign a 1 or 0 to each column\n",
    "df_train = pd.get_dummies(df_train, columns=['Embarked'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked'])\n",
    "\n",
    "# Encode 'Sex' column to 0-Male and 1-Female\n",
    "df_train['Sex'] = df_train['Sex'].apply(lambda x: 1 if 'female' in x else 0)\n",
    "df_test['Sex'] = df_test['Sex'].apply(lambda x: 1 if 'female' in x else 0)\n",
    "\n",
    "# create a new feature called FamilySize that is the sum of SibSp and Parch plus one (the passenger themself).\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "\n",
    "# create a new feature called IsAlone that is 1 if the passenger is alone and 0 otherwise (derived from FamilySize)\n",
    "df_train['IsAlone'] = df_train['FamilySize'].apply(lambda x: 1 if x == 1 else 0)\n",
    "df_test['IsAlone'] = df_test['FamilySize'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# create a new feature called Title that extracts titles from names\n",
    "df_train['Title'] = df_train['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "df_test['Title'] = df_test['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# create a new feature called FareBin that bins the fare into 4 equally sized bins\n",
    "df_train['FareBin'] = pd.qcut(df_train['Fare'], 4)\n",
    "df_test['FareBin'] = pd.qcut(df_test['Fare'], 4)\n",
    "\n",
    "# create a new feature called FareBin_Code that maps the FareBin to a numerical value\n",
    "df_train['FareBin_Code'] = df_train['FareBin'].astype('category').cat.codes\n",
    "df_test['FareBin_Code'] = df_test['FareBin'].astype('category').cat.codes\n",
    "\n",
    "# create a new feature called AgeBin that bins the age into 5 equally sized bins\n",
    "df_train['AgeBin'] = pd.cut(df_train['Age'].astype(int), 5)\n",
    "df_test['AgeBin'] = pd.cut(df_test['Age'].astype(int), 5)\n",
    "\n",
    "# create a new feature called AgeBin_Code that maps the AgeBin to a numerical value\n",
    "df_train['AgeBin_Code'] = df_train['AgeBin'].astype('category').cat.codes\n",
    "df_test['AgeBin_Code'] = df_test['AgeBin'].astype('category').cat.codes\n",
    "\n",
    "df_test['Fare'].fillna(df_test['Fare'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>3</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>3</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Master</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "5                                   Moran, Mr. James    0  27.0      0      0   \n",
       "6                            McCarthy, Mr. Timothy J    0  54.0      0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    0   2.0      3      1   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    1  27.0      0      2   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)    1  14.0      1      0   \n",
       "\n",
       "      Fare  Cabin  Embarked_C  Embarked_Q  Embarked_S  FamilySize  IsAlone  \\\n",
       "0   7.2500      0           0           0           1           2        0   \n",
       "1  71.2833      1           1           0           0           2        0   \n",
       "2   7.9250      0           0           0           1           1        1   \n",
       "3  53.1000      1           0           0           1           2        0   \n",
       "4   8.0500      0           0           0           1           1        1   \n",
       "5   8.4583      0           0           1           0           1        1   \n",
       "6  51.8625      1           0           0           1           1        1   \n",
       "7  21.0750      0           0           0           1           5        0   \n",
       "8  11.1333      0           0           0           1           3        0   \n",
       "9  30.0708      0           1           0           0           2        0   \n",
       "\n",
       "    Title          FareBin  FareBin_Code         AgeBin  AgeBin_Code  \n",
       "0      Mr   (-0.001, 7.91]             0   (16.0, 32.0]            1  \n",
       "1     Mrs  (31.0, 512.329]             3   (32.0, 48.0]            2  \n",
       "2    Miss   (7.91, 14.454]             1   (16.0, 32.0]            1  \n",
       "3     Mrs  (31.0, 512.329]             3   (32.0, 48.0]            2  \n",
       "4      Mr   (7.91, 14.454]             1   (32.0, 48.0]            2  \n",
       "5      Mr   (7.91, 14.454]             1   (16.0, 32.0]            1  \n",
       "6      Mr  (31.0, 512.329]             3   (48.0, 64.0]            3  \n",
       "7  Master   (14.454, 31.0]             2  (-0.08, 16.0]            0  \n",
       "8     Mrs   (7.91, 14.454]             1   (16.0, 32.0]            1  \n",
       "9     Mrs   (14.454, 31.0]             2  (-0.08, 16.0]            0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head(10).to_csv('assets/processed_data.csv', index=False)\n",
    "df_train.head(10)\n",
    "# df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyle0\\AppData\\Local\\Temp\\ipykernel_1656\\3890892284.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_train.corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.034759</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>-0.022998</td>\n",
       "      <td>0.026528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.061956</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>0.316912</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.149683</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>-0.203367</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-0.044492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.344489</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.725541</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.135207</td>\n",
       "      <td>-0.634271</td>\n",
       "      <td>-0.358005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>0.243613</td>\n",
       "      <td>-0.071125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.034759</td>\n",
       "      <td>-0.061956</td>\n",
       "      <td>-0.344489</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.233396</td>\n",
       "      <td>-0.168329</td>\n",
       "      <td>0.099571</td>\n",
       "      <td>0.244228</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>-0.041675</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-0.243612</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.089421</td>\n",
       "      <td>0.942625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.233396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>-0.040460</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>-0.584471</td>\n",
       "      <td>0.393025</td>\n",
       "      <td>-0.218846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.168329</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>-0.583398</td>\n",
       "      <td>0.393881</td>\n",
       "      <td>-0.134014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.099571</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482075</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.162184</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.271832</td>\n",
       "      <td>0.579345</td>\n",
       "      <td>0.124322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.316912</td>\n",
       "      <td>-0.725541</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.244228</td>\n",
       "      <td>-0.040460</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.482075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208528</td>\n",
       "      <td>-0.129572</td>\n",
       "      <td>-0.101139</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>-0.158029</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>0.260538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>-0.001205</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>-0.243292</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>-0.059528</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>0.208528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-0.095298</td>\n",
       "      <td>0.186073</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>-0.033606</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.041675</td>\n",
       "      <td>-0.026354</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.117216</td>\n",
       "      <td>-0.129572</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.086464</td>\n",
       "      <td>-0.240489</td>\n",
       "      <td>-0.079779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.022204</td>\n",
       "      <td>-0.149683</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>-0.162184</td>\n",
       "      <td>-0.101139</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>-0.011668</td>\n",
       "      <td>0.023749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.243612</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>0.217138</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0.077359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.690922</td>\n",
       "      <td>0.465396</td>\n",
       "      <td>-0.216525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAlone</th>\n",
       "      <td>0.057462</td>\n",
       "      <td>-0.203367</td>\n",
       "      <td>0.135207</td>\n",
       "      <td>-0.303646</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>-0.584471</td>\n",
       "      <td>-0.583398</td>\n",
       "      <td>-0.271832</td>\n",
       "      <td>-0.158029</td>\n",
       "      <td>-0.095298</td>\n",
       "      <td>0.086464</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>-0.690922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.560279</td>\n",
       "      <td>0.124650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FareBin_Code</th>\n",
       "      <td>-0.022998</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-0.634271</td>\n",
       "      <td>0.243613</td>\n",
       "      <td>0.089421</td>\n",
       "      <td>0.393025</td>\n",
       "      <td>0.393881</td>\n",
       "      <td>0.579345</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>0.186073</td>\n",
       "      <td>-0.240489</td>\n",
       "      <td>-0.011668</td>\n",
       "      <td>0.465396</td>\n",
       "      <td>-0.560279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBin_Code</th>\n",
       "      <td>0.026528</td>\n",
       "      <td>-0.044492</td>\n",
       "      <td>-0.358005</td>\n",
       "      <td>-0.071125</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>-0.218846</td>\n",
       "      <td>-0.134014</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>0.260538</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.079779</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>-0.216525</td>\n",
       "      <td>0.124650</td>\n",
       "      <td>0.100508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PassengerId  Survived    Pclass       Sex       Age     SibSp  \\\n",
       "PassengerId      1.000000 -0.005007 -0.035144 -0.042939  0.034759 -0.057527   \n",
       "Survived        -0.005007  1.000000 -0.338481  0.543351 -0.061956 -0.035322   \n",
       "Pclass          -0.035144 -0.338481  1.000000 -0.131900 -0.344489  0.083081   \n",
       "Sex             -0.042939  0.543351 -0.131900  1.000000 -0.079306  0.114631   \n",
       "Age              0.034759 -0.061956 -0.344489 -0.079306  1.000000 -0.233396   \n",
       "SibSp           -0.057527 -0.035322  0.083081  0.114631 -0.233396  1.000000   \n",
       "Parch           -0.001652  0.081629  0.018443  0.245489 -0.168329  0.414838   \n",
       "Fare             0.012658  0.257307 -0.549500  0.182333  0.099571  0.159651   \n",
       "Cabin            0.019919  0.316912 -0.725541  0.140391  0.244228 -0.040460   \n",
       "Embarked_C      -0.001205  0.168240 -0.243292  0.082853  0.029167 -0.059528   \n",
       "Embarked_Q      -0.033606  0.003650  0.221009  0.074115 -0.041675 -0.026354   \n",
       "Embarked_S       0.022204 -0.149683  0.074053 -0.119224  0.000674  0.068734   \n",
       "FamilySize      -0.040143  0.016639  0.065997  0.200988 -0.243612  0.890712   \n",
       "IsAlone          0.057462 -0.203367  0.135207 -0.303646  0.166664 -0.584471   \n",
       "FareBin_Code    -0.022998  0.299357 -0.634271  0.243613  0.089421  0.393025   \n",
       "AgeBin_Code      0.026528 -0.044492 -0.358005 -0.071125  0.942625 -0.218846   \n",
       "\n",
       "                 Parch      Fare     Cabin  Embarked_C  Embarked_Q  \\\n",
       "PassengerId  -0.001652  0.012658  0.019919   -0.001205   -0.033606   \n",
       "Survived      0.081629  0.257307  0.316912    0.168240    0.003650   \n",
       "Pclass        0.018443 -0.549500 -0.725541   -0.243292    0.221009   \n",
       "Sex           0.245489  0.182333  0.140391    0.082853    0.074115   \n",
       "Age          -0.168329  0.099571  0.244228    0.029167   -0.041675   \n",
       "SibSp         0.414838  0.159651 -0.040460   -0.059528   -0.026354   \n",
       "Parch         1.000000  0.216225  0.036987   -0.011069   -0.081228   \n",
       "Fare          0.216225  1.000000  0.482075    0.269335   -0.117216   \n",
       "Cabin         0.036987  0.482075  1.000000    0.208528   -0.129572   \n",
       "Embarked_C   -0.011069  0.269335  0.208528    1.000000   -0.148258   \n",
       "Embarked_Q   -0.081228 -0.117216 -0.129572   -0.148258    1.000000   \n",
       "Embarked_S    0.060814 -0.162184 -0.101139   -0.782742   -0.499421   \n",
       "FamilySize    0.783111  0.217138 -0.009175   -0.046215   -0.058592   \n",
       "IsAlone      -0.583398 -0.271832 -0.158029   -0.095298    0.086464   \n",
       "FareBin_Code  0.393881  0.579345  0.500936    0.186073   -0.240489   \n",
       "AgeBin_Code  -0.134014  0.124322  0.260538    0.030200   -0.079779   \n",
       "\n",
       "              Embarked_S  FamilySize   IsAlone  FareBin_Code  AgeBin_Code  \n",
       "PassengerId     0.022204   -0.040143  0.057462     -0.022998     0.026528  \n",
       "Survived       -0.149683    0.016639 -0.203367      0.299357    -0.044492  \n",
       "Pclass          0.074053    0.065997  0.135207     -0.634271    -0.358005  \n",
       "Sex            -0.119224    0.200988 -0.303646      0.243613    -0.071125  \n",
       "Age             0.000674   -0.243612  0.166664      0.089421     0.942625  \n",
       "SibSp           0.068734    0.890712 -0.584471      0.393025    -0.218846  \n",
       "Parch           0.060814    0.783111 -0.583398      0.393881    -0.134014  \n",
       "Fare           -0.162184    0.217138 -0.271832      0.579345     0.124322  \n",
       "Cabin          -0.101139   -0.009175 -0.158029      0.500936     0.260538  \n",
       "Embarked_C     -0.782742   -0.046215 -0.095298      0.186073     0.030200  \n",
       "Embarked_Q     -0.499421   -0.058592  0.086464     -0.240489    -0.079779  \n",
       "Embarked_S      1.000000    0.077359  0.029074     -0.011668     0.023749  \n",
       "FamilySize      0.077359    1.000000 -0.690922      0.465396    -0.216525  \n",
       "IsAlone         0.029074   -0.690922  1.000000     -0.560279     0.124650  \n",
       "FareBin_Code   -0.011668    0.465396 -0.560279      1.000000     0.100508  \n",
       "AgeBin_Code     0.023749   -0.216525  0.124650      0.100508     1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the correlation between different numerical columns\n",
    "df_train.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the correlation matrix with focus on the 'Survived' variable:\n",
    "\n",
    "1. **Sex**: This variable is highly positively correlated with Survived (0.543351), indicating that women were more likely to survive than men.\n",
    "2. **Pclass**: This variable is negatively correlated with Survived (-0.338481), suggesting that people in higher classes (lower number) had a better chance of survival.\n",
    "3. **Fare and FareBin_Code**: These variables have positive correlation with Survived (0.257307 and 0.299357 respectively), suggesting that passengers who paid more were more likely to survive. This makes sense as the fare is also linked with the class.\n",
    "4. **Cabin**: This variable is positively correlated with Survived (0.316912), which suggests that those who had a cabin were more likely to survive. This might be related to the class of the passenger as well.\n",
    "5. **Embarked_C**: This variable is positively correlated with Survived (0.168240), suggesting that passengers who embarked at Cherbourg (C) had a higher survival rate.\n",
    "6. **Embarked_S**: This variable is negatively correlated with Survived (-0.149683), suggesting that passengers who embarked at Southampton (S) had a lower survival rate.\n",
    "7. **Age and AgeBin_Code**: Age is slightly negatively correlated with survival (-0.064910 and -0.044492 respectively), implying that younger passengers were slightly more likely to survive.\n",
    "8. **IsAlone**: This variable is negatively correlated with Survived (-0.203367), suggesting that those who travelled alone were less likely to survive.\n",
    "\n",
    "The other variables ('PassengerId', 'SibSp', 'Parch', 'Embarked_Q', 'FamilySize') show a weak correlation with Survived and may not be as significant.\n",
    "\n",
    "Please remember, while these interpretations give an idea about the relationships, correlation does not imply causation. The exact causal relationships can be more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FareBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex     Fare  Cabin  Embarked_C  Embarked_S  \\\n",
       "0            1         0       3    0   7.2500      0           0           1   \n",
       "1            2         1       1    1  71.2833      1           1           0   \n",
       "2            3         1       3    1   7.9250      0           0           1   \n",
       "3            4         1       1    1  53.1000      1           0           1   \n",
       "4            5         0       3    0   8.0500      0           0           1   \n",
       "\n",
       "   IsAlone  FareBin_Code  \n",
       "0        0             0  \n",
       "1        0             3  \n",
       "2        1             1  \n",
       "3        0             3  \n",
       "4        1             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's keep only columns that have a correlation of at least 0.1 or -0.1 with the 'Survived' column\n",
    "df_train = df_train[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Fare', 'Cabin', 'Embarked_C', 'Embarked_S', 'IsAlone', 'FareBin_Code']]\n",
    "df_test = df_test[['PassengerId', 'Pclass', 'Sex', 'Fare', 'Cabin', 'Embarked_C', 'Embarked_S', 'IsAlone', 'FareBin_Code']]\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the accuracy of your predictions, you would need a ground truth - the actual outcomes that our model was trying to predict.\n",
    "\n",
    "In a normal train/test split situation, you would have the ground truth for your test set, so you could compare our model's predictions directly to the real outcomes. Common metrics for this comparison include accuracy, precision, recall, F1 score, ROC AUC, etc.\n",
    "\n",
    "However, in the case of the Titanic dataset from Kaggle, the ground truth (i.e., whether each passenger in the test set survived or not) is not provided. The test set predictions are meant to be submitted to Kaggle, which then computes the accuracy of your model and provides you with a score.\n",
    "\n",
    "If we want to get a sense of our model's accuracy before submitting to Kaggle, we could split the original training data into a smaller training set and a validation set. We can train our model on this smaller training set and then test it on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (712, 9)\n",
      "Validation data shape:  (179, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features (X) from the target variable (Y)\n",
    "X = df_train.drop('Survived', axis=1)\n",
    "Y = df_train['Survived']\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score:  0.7932960893854749\n",
      "Logistic Regression Score:  0.776536312849162\n",
      "Support Vector Machine Score:  0.5977653631284916\n",
      "Gradient Boosting Score:  0.8156424581005587\n",
      "\n",
      "Best Model is Gradient Boosting with score: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# let's test a few more models to see which one gives the best score and then submit to kaggle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a dictionary of the models\n",
    "model_dict = {'Random Forest': RandomForestClassifier(),\n",
    "              'Logistic Regression': LogisticRegression(),\n",
    "              'Support Vector Machine': SVC(),\n",
    "              'Gradient Boosting': GradientBoostingClassifier()}\n",
    "\n",
    "# Initialize best score and best model name\n",
    "best_score = 0\n",
    "best_model_name = ''\n",
    "\n",
    "# Iterate over each model in the dictionary\n",
    "for model_name, model in model_dict.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    model_score = model.score(X_val, Y_val)\n",
    "    print(f'{model_name} Score: ', model_score)\n",
    "\n",
    "    # Update the best_score and best_model_name\n",
    "    if model_score > best_score:\n",
    "        best_score = model_score\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f'\\nBest Model is {best_model_name} with score: {best_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Instantiate the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbc.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = gbc.predict(df_test)\n",
    "\n",
    "# Prepare the predictions for Kaggle submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': df_test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this is the best score on Kaggle. We can tune the hyperparameters of the Gradient Boosting Classifer and use Grid Search to find the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameters we want to test\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Create a GradientBoostingClassifier object\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the optimal parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.7932960893854749\n"
     ]
    }
   ],
   "source": [
    "# Create a new GradientBoostingClassifier with the best parameters\n",
    "gbc_best = GradientBoostingClassifier(n_estimators=400, max_depth=2, learning_rate=0.01)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbc_best.fit(X_train, Y_train)\n",
    "\n",
    "# Get the score on the validation data\n",
    "print(\"Validation accuracy: \", gbc_best.score(X_val, Y_val))\n",
    "\n",
    "# Predict the outcomes on the actual test data\n",
    "predictions = gbc_best.predict(df_test)\n",
    "\n",
    "# Create a new DataFrame for the submission\n",
    "submission = pd.DataFrame({'PassengerId':df_test['PassengerId'], 'Survived':predictions})\n",
    "\n",
    "# Save the submission to a csv file\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
